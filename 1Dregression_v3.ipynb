{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "1Dregression_v3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvicky30/Deep_neural_Networks_PyToacrch/blob/master/1Dregression_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3MiZrUbZaO9",
        "colab_type": "text"
      },
      "source": [
        "<h1>Linear Regression 1D: Prediction</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrT-pj86ZaO_",
        "colab_type": "text"
      },
      "source": [
        "<h2>Table of Contents</h2>\n",
        "<p>In this lab, we will  review how to make a prediction in several different ways by using PyTorch.</h2>\n",
        "<ul>\n",
        "    <li><a href=\"#Prediction\">Prediction</a></li>\n",
        "    <li><a href=\"#Linear\">Class Linear</a></li>\n",
        "    <li><a href=\"#Cust\">Build Custom Modules</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>15 min</strong></p>\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CJqaM32ZaPC",
        "colab_type": "text"
      },
      "source": [
        "<h2>Preparation</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNZVwRPQZaPE",
        "colab_type": "text"
      },
      "source": [
        "The following are the libraries we are going to use for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GojZi_mrZaPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAPs9wzsZaPR",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCLbtDctZaPT",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Prediction\">Prediction</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBBMwQyHZaPU",
        "colab_type": "text"
      },
      "source": [
        "Let us create the following expressions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u9jxDbeZaPV",
        "colab_type": "text"
      },
      "source": [
        "$b=-1,w=2$\n",
        "\n",
        "$\\hat{y}=-1+2x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSPv8Tk4ZaPW",
        "colab_type": "text"
      },
      "source": [
        "First, define the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6alfvdm3ZaPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define w = 2 and b = -1 for y = wx + b\n",
        "\n",
        "w = torch.tensor(2.0, requires_grad = True)\n",
        "b = torch.tensor(-1.0, requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0IBIawsZaPc",
        "colab_type": "text"
      },
      "source": [
        "Then, define the function <code>forward(x, w, b)</code> makes the prediction: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh73nSruZaPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function forward(x) for prediction\n",
        "\n",
        "def forward(x):\n",
        "    yhat = w * x + b\n",
        "    return yhat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0cSP3DyZaPh",
        "colab_type": "text"
      },
      "source": [
        "Let's make the following prediction at <i>x = 1</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jwZ9ZAEZaPi",
        "colab_type": "text"
      },
      "source": [
        "$\\hat{y}=-1+2x$\n",
        "\n",
        "$\\hat{y}=-1+2(1)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0i1doT-ZaPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c8a7287-8482-4f2e-b840-09a98547b4cf"
      },
      "source": [
        "# Predict y = 2x - 1 at x = 1\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WchMjF5VZaPn",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCn0Jln4ZaPo",
        "colab_type": "text"
      },
      "source": [
        "Now, let us try to make the prediction for multiple inputs:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhTW5MLvZaPp",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2.png\" width=\"500\" alt=\"Linear Regression Multiple Input Samples\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwrbL4g5ZaPq",
        "colab_type": "text"
      },
      "source": [
        "Let us construct the <code>x</code> tensor first. Check the shape of <code>x</code>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGGhpiVtZaPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "824139dd-8aed-439f-dfc1-f5caf07b09f7"
      },
      "source": [
        "# Create x Tensor and check the shape of x tensor\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "print(\"The shape of x: \", x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of x:  torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmlBNK5zZaPu",
        "colab_type": "text"
      },
      "source": [
        "Now make the prediction: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha2RywvnZaPv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a20f7be9-02d4-4913-d225-61d6cd1033ce"
      },
      "source": [
        "# Make the prediction of y = 2x - 1 at x = [1, 2]\n",
        "\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.],\n",
            "        [3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYUmga6qZaPy",
        "colab_type": "text"
      },
      "source": [
        "The result is the same as what it is in the image above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvXsqUD2ZaPy",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9xM6h87ZaPz",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F0_ahA8ZaP0",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction of the following <code>x</code> tensor using the <code>w</code> and <code>b</code> from above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DB8zl0ZZaP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "fe81ed65-dc41-434d-aa68-0ff0bb34afa0"
      },
      "source": [
        "# Practice: Make a prediction of y = 2x - 1 at x = [[1.0], [2.0], [3.0]]\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.],\n",
            "        [3.],\n",
            "        [5.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h_WIr-FZaP5",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmMHQHauZaP6",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Linear\">Class Linear</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SQKFmfbZaP7",
        "colab_type": "text"
      },
      "source": [
        "The linear class can be used to make a prediction. We can also use the linear class to build more complex models. Let's import the module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub1R2d_SZaP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Class Linear\n",
        "\n",
        "from torch.nn import Linear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytPWhkrlZaP-",
        "colab_type": "text"
      },
      "source": [
        "Set the random seed because the parameters are randomly initialized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fpjSJpiZaP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f105439-7130-44ba-fc94-4aea7c9d191c"
      },
      "source": [
        "# Set random seed\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fdb73cc7a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js6CnAcYZaQC",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz7cNVz0ZaQD",
        "colab_type": "text"
      },
      "source": [
        "Let us create the linear object by using the constructor. The parameters are randomly created. Let us print out to see what <i>w</i> and <i>b</i>. The parameters of an <code>torch.nn.Module</code> model are contained in the modelâ€™s parameters accessed with <code>lr.parameters()</code>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSfCryvmZaQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "472fc27b-d92c-4b5c-96a6-fa16dd1bd29a"
      },
      "source": [
        "# Create Linear Regression Model, and print out the parameters\n",
        "\n",
        "lr = Linear(in_features=1, out_features=1, bias=True)\n",
        "print(\"Parameters w and b: \", list(lr.parameters()))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters w and b:  [Parameter containing:\n",
            "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4694], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naf5lECZZaQH",
        "colab_type": "text"
      },
      "source": [
        "This is equivalent to the following expression:  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbQtPyIoZaQH",
        "colab_type": "text"
      },
      "source": [
        "$b=-0.44, w=0.5153$\n",
        "\n",
        "$\\hat{y}=-0.44+0.5153x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhR45V1IZaQI",
        "colab_type": "text"
      },
      "source": [
        "A method  <code>state_dict()</code> Returns a Python dictionary object corresponding to the layers of each parameter  tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2EvMe1yZaQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ce448989-cd8e-4194-aa6b-e4990d1ac04a"
      },
      "source": [
        "print(\"Python dictionary: \",lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python dictionary:  OrderedDict([('weight', tensor([[-0.1939]])), ('bias', tensor([0.4694]))])\n",
            "keys:  odict_keys(['weight', 'bias'])\n",
            "values:  odict_values([tensor([[-0.1939]]), tensor([0.4694])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUr1ZWHcZaQP",
        "colab_type": "text"
      },
      "source": [
        "The keys correspond to the name of the attributes and the values correspond to the parameter value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e-k7QVyZaQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e6b2847c-ecd4-4025-bc77-a54fc2a9e2c4"
      },
      "source": [
        "print(\"weight:\",lr.weight)\n",
        "print(\"bias:\",lr.bias)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight: Parameter containing:\n",
            "tensor([[-0.1939]], requires_grad=True)\n",
            "bias: Parameter containing:\n",
            "tensor([0.4694], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A7yFfiZZaQU",
        "colab_type": "text"
      },
      "source": [
        "Now let us make a single prediction at <i>x = [[1.0]]</i>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1y8bl2VZaQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b2dfa17-0e14-4097-fc2b-89684fb406d2"
      },
      "source": [
        "# Make the prediction at x = [[1.0]]\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.2755]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvBqqZHKZaQa",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkp0HAiNZaQb",
        "colab_type": "text"
      },
      "source": [
        "Similarly, you can make multiple predictions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_gQHcK4ZaQc",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2vector_function.png\" width=\"500\" alt=\"Linear Class Sample with Multiple Inputs\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rysmu-eZaQc",
        "colab_type": "text"
      },
      "source": [
        "Use model <code>lr(x)</code> to predict the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2mZeLDqZaQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0824ee50-2bf2-4081-ed31-19405d080fdc"
      },
      "source": [
        "# Create the prediction using linear model\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.2755],\n",
            "        [0.0816]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvMDxUxLZaQi",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmT8oMUrZaQj",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRYcuQK0ZaQk",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction of the following <code>x</code> tensor using the linear regression model <code>lr</code>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IGQf5l5ZaQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "613356b1-a31a-40bd-8e68-e91c4322ee6b"
      },
      "source": [
        "# Practice: Use the linear regression model object lr to make the prediction.\n",
        "\n",
        "x = torch.tensor([[1.0],[2.0],[3.0]])\n",
        "yhat = lr(x)\n",
        "print(\"the predictions\",yhat)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the predictions tensor([[ 0.2755],\n",
            "        [ 0.0816],\n",
            "        [-0.1122]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB2hMj84ZaQr",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZZPIHJaZaQs",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Cust\">Build Custom Modules</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40KVOHGKZaQt",
        "colab_type": "text"
      },
      "source": [
        "Now, let's build a custom module. We can make more complex models by using this method later on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z2QAYTAZaQu",
        "colab_type": "text"
      },
      "source": [
        "First, import the following library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvZvJqENZaQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Library for this section\n",
        "\n",
        "from torch import nn"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iq-KMlqZaQ1",
        "colab_type": "text"
      },
      "source": [
        "Now, let us define the class: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYfoX5h8ZaQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Customize Linear Regression Class\n",
        "\n",
        "class LR(nn.Module):  #as LR is now sub-class of the nn.Module\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, input_size, output_size):\n",
        "        \n",
        "        # Inherit from parent\n",
        "        super(LR, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "    \n",
        "    # Prediction function\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXsTt09lZaQ5",
        "colab_type": "text"
      },
      "source": [
        "Create an object by using the constructor. Print out the parameters we get and the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axWbYLuJZaQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "050b75c4-c9e9-4749-e8a0-6e59dbecabfd"
      },
      "source": [
        "# Create the linear regression model. Print out the parameters.\n",
        "\n",
        "lr = LR(1, 1) #create lr(object of class LR)\n",
        "print(\"The parameters: \", list(lr.parameters()))\n",
        "print(\"Linear model: \", lr.linear)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters:  [Parameter containing:\n",
            "tensor([[-0.9414]], requires_grad=True), Parameter containing:\n",
            "tensor([0.5997], requires_grad=True)]\n",
            "Linear model:  Linear(in_features=1, out_features=1, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sn0Y3fiZaQ_",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2XkU-aFZaRA",
        "colab_type": "text"
      },
      "source": [
        "Let us try to make a prediction of a single input sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEnqdzwOZaRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac0b0882-7e35-404c-8faa-2d1149b62505"
      },
      "source": [
        "# Try our customize linear regression model with single input\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[-0.3417]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icu8aHBaZaRE",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNCfAs9LZaRF",
        "colab_type": "text"
      },
      "source": [
        "Now, let us try another example with multiple samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwWw6ZjPZaRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "89f923ac-084f-4c8a-daf0-71db49db6329"
      },
      "source": [
        "# Try our customize linear regression model with multiple input\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[-0.3417],\n",
            "        [-1.2832]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NBDI7mgZaRK",
        "colab_type": "text"
      },
      "source": [
        "the parameters are also stored in an ordered dictionary :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0vzqNE-ZaRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a408b1cd-b780-4b27-a6ee-f1dd36c49fb4"
      },
      "source": [
        "print(\"Python dictionary: \", lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python dictionary:  OrderedDict([('linear.weight', tensor([[-0.9414]])), ('linear.bias', tensor([0.5997]))])\n",
            "keys:  odict_keys(['linear.weight', 'linear.bias'])\n",
            "values:  odict_values([tensor([[-0.9414]]), tensor([0.5997])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lUfYc1kZaRS",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqO8vvnvZaRT",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7jEG99wZaRU",
        "colab_type": "text"
      },
      "source": [
        "Create an object <code>lr1</code> from the class we created before and make a prediction by using the following tensor: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvWpb5znZaRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ebf14151-2b37-4f46-a82a-5454862972a4"
      },
      "source": [
        "# Practice: Use the LR class to create a model and make a prediction of the following tensor.\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "mylr=LR(1,1)\n",
        "yhat = mylr(x)\n",
        "print(\"predictions from costomized liner regression model:\",yhat)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions from costomized liner regression model: tensor([[ 0.3030],\n",
            "        [ 0.0973],\n",
            "        [-0.1084]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}